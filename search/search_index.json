{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Tracer Backend","title":"Home"},{"location":"#tracer-backend","text":"","title":"Tracer Backend"},{"location":"Logger/","text":"Use of this system is deprecated due to lack of workforce to build entire system to support LoggerQuery. TracerLogger This Document explains Internal Working as well as Usage of TracerLogger Overview TracerLogger is nothing but a Mapper which maps Interface to LoggingInterface . Whenever a log request is received, it identifies associated LoggingInterface and forwards that request to that interface. Note Main logic stays in LoggingInterface. TracerLogger is just a manager for these interfaces. from Logger import TracerLogger, LoggingInterface logger = TracerLogger() logger.logError('InterfaceName', 'Message', 'UniqueKey') LoggingInterface Whenever you write a large scale application, you split it into layers . Here, in Tracer, we refer each level as interface. Consider analogy from OSI model. Everything is segregated into levels. Here, in Tracer, levels or Interfaces are Router , Interfaces , Data_Functions . Each request has to go through there levels/Interface. More details on levels mentioned here. Link to be added later. So, TracerLogger takes in array if these interfaces so you don't have to manage location of log data and you dont waste time in finding your logs. from Logger import LoggingInterface interface = LoggingInterface('Name') Now, every LoggingInterface as three logging levels implemented, namely Error , Info , Debug . Each logging level has a separate file and is continuosly logError() LoggingInterface.errorLog(message, uniqueid) This method will write to file /logs/interfacename/error.log logInfo() LoggingInterface.logInfo(message, uniqueid) This method will write to file /logs/interfacename/info.log logDebug() LoggingInterface.logDebug(message, uniqueid) This method will write to file /logs/interfacename/debug.log LoggerQuery This class will be used to track errors. It will allow user to do basic querying over their log files. This class's functionality is divided into two parts: 1. Re-create logging maps and re-initialize some parts. 2. Answer to queries. 1. Re-create LoggingMaps and Re-Initialize some parts. This is done because LoggingInterface and LoggerQuery my be on different memory since, user may not necessarily create LoggerQuery in same program. Also, by doing this step, LoggerQuery becomes stateless, i. e. it will not depend on runnning instance and can be used as \"tool\". Working : As soon as instance is created, we scan for all existing folders in /logs/ . This will give us interfaces which were created, since, each interface has its own folder. Once we have array of interface names, we initialise indivisual logging instance and create a map with key as InterfaceName and value as reference to LoggingInterface . By doing this, we have statelessly generated most of the contents of TracerLogger which was used while creating logs, or in case of server, which is being used while creating log Statelesly !! Note that everything mentioned above is a part of constructor and no public methods are expected in this case 2. Answer Queries. This functionality will be responsible for efficient delivery of collected logs. LoggerQuery.traceByID(uniqueid, startTime=None, endTime=None) : * Used for tracing a request. * Returns Map with key being InterfaceName and value being Map with key being LogLevel and value Being list of Logs collected in given time range.(If any. Else everything will be returned). * Working : We traverse through all files using filehandlers associated with LoggingInterface in re-created Map. Then, using Regex , we get data into memory, filter out time constraints and return it. Once everything is collected, we map it according to return type in above point and return. Note: Task of serving those files is left on caller. LoggerQuery.trackAllErrors(startTime=None, endTime=None) : * Used for tracking all Errors. * Returns a Map with key being InterfaceName and value being list of all errors under that interface. * Working : We traverse through filehandlers associated with interfaces and read and parse all error.log file. Then we filter out according to given time constraints, arrange according to return value mentioned and return. LoggerQuery.trackAllInfo(startTime=None, endTime=None) : * Same as above. LoggerQuery.trackAllDebug(startTime=None, endTime=None) : * Same as above.","title":"Logger"},{"location":"Logger/#tracerlogger","text":"This Document explains Internal Working as well as Usage of TracerLogger","title":"TracerLogger"},{"location":"Logger/#overview","text":"TracerLogger is nothing but a Mapper which maps Interface to LoggingInterface . Whenever a log request is received, it identifies associated LoggingInterface and forwards that request to that interface. Note Main logic stays in LoggingInterface. TracerLogger is just a manager for these interfaces. from Logger import TracerLogger, LoggingInterface logger = TracerLogger() logger.logError('InterfaceName', 'Message', 'UniqueKey')","title":"Overview"},{"location":"Logger/#logginginterface","text":"Whenever you write a large scale application, you split it into layers . Here, in Tracer, we refer each level as interface. Consider analogy from OSI model. Everything is segregated into levels. Here, in Tracer, levels or Interfaces are Router , Interfaces , Data_Functions . Each request has to go through there levels/Interface. More details on levels mentioned here. Link to be added later. So, TracerLogger takes in array if these interfaces so you don't have to manage location of log data and you dont waste time in finding your logs. from Logger import LoggingInterface interface = LoggingInterface('Name') Now, every LoggingInterface as three logging levels implemented, namely Error , Info , Debug . Each logging level has a separate file and is continuosly","title":"LoggingInterface"},{"location":"Logger/#logerror","text":"LoggingInterface.errorLog(message, uniqueid) This method will write to file /logs/interfacename/error.log","title":"logError()"},{"location":"Logger/#loginfo","text":"LoggingInterface.logInfo(message, uniqueid) This method will write to file /logs/interfacename/info.log","title":"logInfo()"},{"location":"Logger/#logdebug","text":"LoggingInterface.logDebug(message, uniqueid) This method will write to file /logs/interfacename/debug.log","title":"logDebug()"},{"location":"Logger/#loggerquery","text":"This class will be used to track errors. It will allow user to do basic querying over their log files. This class's functionality is divided into two parts: 1. Re-create logging maps and re-initialize some parts. 2. Answer to queries.","title":"LoggerQuery"},{"location":"Logger/#1-re-create-loggingmaps-and-re-initialize-some-parts","text":"This is done because LoggingInterface and LoggerQuery my be on different memory since, user may not necessarily create LoggerQuery in same program. Also, by doing this step, LoggerQuery becomes stateless, i. e. it will not depend on runnning instance and can be used as \"tool\". Working : As soon as instance is created, we scan for all existing folders in /logs/ . This will give us interfaces which were created, since, each interface has its own folder. Once we have array of interface names, we initialise indivisual logging instance and create a map with key as InterfaceName and value as reference to LoggingInterface . By doing this, we have statelessly generated most of the contents of TracerLogger which was used while creating logs, or in case of server, which is being used while creating log Statelesly !! Note that everything mentioned above is a part of constructor and no public methods are expected in this case","title":"1. Re-create LoggingMaps and Re-Initialize some parts."},{"location":"Logger/#2-answer-queries","text":"This functionality will be responsible for efficient delivery of collected logs. LoggerQuery.traceByID(uniqueid, startTime=None, endTime=None) : * Used for tracing a request. * Returns Map with key being InterfaceName and value being Map with key being LogLevel and value Being list of Logs collected in given time range.(If any. Else everything will be returned). * Working : We traverse through all files using filehandlers associated with LoggingInterface in re-created Map. Then, using Regex , we get data into memory, filter out time constraints and return it. Once everything is collected, we map it according to return type in above point and return. Note: Task of serving those files is left on caller. LoggerQuery.trackAllErrors(startTime=None, endTime=None) : * Used for tracking all Errors. * Returns a Map with key being InterfaceName and value being list of all errors under that interface. * Working : We traverse through filehandlers associated with interfaces and read and parse all error.log file. Then we filter out according to given time constraints, arrange according to return value mentioned and return. LoggerQuery.trackAllInfo(startTime=None, endTime=None) : * Same as above. LoggerQuery.trackAllDebug(startTime=None, endTime=None) : * Same as above.","title":"2. Answer Queries."},{"location":"about/","text":"","title":"About"},{"location":"backendar/","text":"","title":"Backend Architecture"},{"location":"caching/","text":"","title":"Caching"},{"location":"endpoints/","text":"Endpoints Used by Frontend Login POST /login Headers Content-Type: application/json Payload { \"email\" : \"<email>\", \"password\" : \"<password>\" } Response If Login Success: { \"STATUS\" : \"OK\", \"TOKEN\" : \"<accesstoken>\" } If Login Fail: { \"STATUS\" : \"FAIL\" } Register POST /register Headers Content-Type: application/json Payload { \"name\" : \"<name>\", \"email\" : \"<email>\", \"password\" : \"<password>\" } Response If Email Verification Fail: { \"STATUS\" : \"FAIL\", \"ERROR\" : \"\" } If Password Validation Fail: { \"STATUS\" : \"FAIL\" } If Email Unique Validation Fail: { \"STATUS\" : \"FAIL\" } If All Above Validation Success: { \"STATUS\" : \"OK\", \"TOKEN\" : \"<accesstoken>\" } Topup POST /topup Headers Content-Type: application/json Token : <accesstoken> Response If Topup Success: { \"STATUS\" : \"OK\" } If Topup Fail (Less than 20 minutes delay between 2 topups): { \"STATUS\" : \"FAIL\" } URL POST /url Headers Content-Type: application/json Token : <accesstoken> Payload { \"redirect_url\" : \"<redirect_url>\" } Response If Url Validation Success: { \"STATUS\" : \"OK\" } If Url Validation Fail: { \"STATUS\" : \"FAIL\", \"URL_ID\" : \"<url_id>\" } GET /url Headers Content-Type: application/json Token : <accesstoken> Response If Urls Under User Fetched Success: { \"STATUS\" : \"OK\", \"DATA\" : [ { \"_id\":\"<urlid>\", \"redirect_url\":\"<redirect target>\", \"created_date\":\"<timestamp>\", \"hits\":\"<total hits>\" } . . ] } If Urls Under User Fetched Fail: { \"STATUS\" : \"FAIL\" } Specific URL GET /url/data/:id Headers Content-Type: application/json token: <accesstoken> Response { \"STATUS\":\"OK\", \"DATA\" : [ { \"_id\": uniqueid(collection id for mongodb), \"battery\": battery, \"platform\": platform, \"language\": language, \"userAgent\": user_agent, \"availableRam\": available_ram, \"availableCores\": available_cores, \"locationData\" : { \"city\" : city, \"region\": region, \"postal\" : postal, \"org\" : isp, \"location\": { \"lat\":latitude, \"long\":longitude } } } . . . ] } GET /url/locations/:id Headers Content-Type: application/json token: <accesstoken> Response { \"STATUS\" : \"OK\", \"DATA\" : [ { \"_id\" : uniqueid(collection id for mongodb), \"lat\" : latitude, \"long\": longitude } . . . ] }","title":"Endpoints"},{"location":"endpoints/#endpoints-used-by-frontend","text":"","title":"Endpoints Used by Frontend"},{"location":"endpoints/#login","text":"POST /login","title":"Login"},{"location":"endpoints/#headers","text":"Content-Type: application/json","title":"Headers"},{"location":"endpoints/#payload","text":"{ \"email\" : \"<email>\", \"password\" : \"<password>\" }","title":"Payload"},{"location":"endpoints/#response","text":"If Login Success: { \"STATUS\" : \"OK\", \"TOKEN\" : \"<accesstoken>\" } If Login Fail: { \"STATUS\" : \"FAIL\" }","title":"Response"},{"location":"endpoints/#register","text":"POST /register","title":"Register"},{"location":"endpoints/#headers_1","text":"Content-Type: application/json","title":"Headers"},{"location":"endpoints/#payload_1","text":"{ \"name\" : \"<name>\", \"email\" : \"<email>\", \"password\" : \"<password>\" }","title":"Payload"},{"location":"endpoints/#response_1","text":"If Email Verification Fail: { \"STATUS\" : \"FAIL\", \"ERROR\" : \"\" } If Password Validation Fail: { \"STATUS\" : \"FAIL\" } If Email Unique Validation Fail: { \"STATUS\" : \"FAIL\" } If All Above Validation Success: { \"STATUS\" : \"OK\", \"TOKEN\" : \"<accesstoken>\" }","title":"Response"},{"location":"endpoints/#topup","text":"POST /topup","title":"Topup"},{"location":"endpoints/#headers_2","text":"Content-Type: application/json Token : <accesstoken>","title":"Headers"},{"location":"endpoints/#response_2","text":"If Topup Success: { \"STATUS\" : \"OK\" } If Topup Fail (Less than 20 minutes delay between 2 topups): { \"STATUS\" : \"FAIL\" }","title":"Response"},{"location":"endpoints/#url","text":"POST /url","title":"URL"},{"location":"endpoints/#headers_3","text":"Content-Type: application/json Token : <accesstoken>","title":"Headers"},{"location":"endpoints/#payload_2","text":"{ \"redirect_url\" : \"<redirect_url>\" }","title":"Payload"},{"location":"endpoints/#response_3","text":"If Url Validation Success: { \"STATUS\" : \"OK\" } If Url Validation Fail: { \"STATUS\" : \"FAIL\", \"URL_ID\" : \"<url_id>\" } GET /url","title":"Response"},{"location":"endpoints/#headers_4","text":"Content-Type: application/json Token : <accesstoken>","title":"Headers"},{"location":"endpoints/#response_4","text":"If Urls Under User Fetched Success: { \"STATUS\" : \"OK\", \"DATA\" : [ { \"_id\":\"<urlid>\", \"redirect_url\":\"<redirect target>\", \"created_date\":\"<timestamp>\", \"hits\":\"<total hits>\" } . . ] } If Urls Under User Fetched Fail: { \"STATUS\" : \"FAIL\" }","title":"Response"},{"location":"endpoints/#specific-url","text":"GET /url/data/:id","title":"Specific URL"},{"location":"endpoints/#headers_5","text":"Content-Type: application/json token: <accesstoken>","title":"Headers"},{"location":"endpoints/#response_5","text":"{ \"STATUS\":\"OK\", \"DATA\" : [ { \"_id\": uniqueid(collection id for mongodb), \"battery\": battery, \"platform\": platform, \"language\": language, \"userAgent\": user_agent, \"availableRam\": available_ram, \"availableCores\": available_cores, \"locationData\" : { \"city\" : city, \"region\": region, \"postal\" : postal, \"org\" : isp, \"location\": { \"lat\":latitude, \"long\":longitude } } } . . . ] } GET /url/locations/:id","title":"Response"},{"location":"endpoints/#headers_6","text":"Content-Type: application/json token: <accesstoken>","title":"Headers"},{"location":"endpoints/#response_6","text":"{ \"STATUS\" : \"OK\", \"DATA\" : [ { \"_id\" : uniqueid(collection id for mongodb), \"lat\" : latitude, \"long\": longitude } . . . ] }","title":"Response"},{"location":"scheduler/","text":"","title":"Scheduler"}]}